- Multi-arm bandit implemented using greedy-epsilon strategy.

- Tuning our probability epsilon dictates the balance between exploration and exploitation.

- Either agent picks random decision, or picks highest estimated value based on past experiences.

- Consider the position of the agent and the direction it takes. If it has moved to a better place,
it will need to have been rewarded. If it gets rewarded, we should make note of where it started and
in which direction it moved. In the future, when it finds itself in the same position, we access this
memory and judge that through the history of moves from certain positions using certain moves, and the
reward associated with that, we can give a highest estimated value based on that one.

- This is a naive approach and I have almost certainly overlooked things.

- State space of Gridworld is 10x10.

- Actions draw from a set of 4.

- Rewards are numerical values derived from arriving at certain states.

- Policy is a snapshot of the best action to take at any given state of the simulation.

- Maximise the future discounted reward. Future rewards are worth less than immediate rewards,
and as such are weighted by multiplying against a coefficient y or gamma.

- Regret as a keyword is the difference between the rewards obtained by the system and the rewards
that could have been obtained by choosing the best action at each state within the given window.

- Estimated action values can be updated based on the rewards received in the past, but also and very
importantly according to how many times this action has been taken. For example, if it was taken once
with a high reward, then this is less valuable than if it was taken many times with a consistently
high reward.

- Recommending news articles, you serve a random article and in order to know whether or not the user
appreciated the little piece of exploration and found reward in it, you have to categorise what a reward
looks like. It could be a literal thumbs up or rating from the user, or it could be time spent browsing,
etc. Seems closely related to A/B testing.